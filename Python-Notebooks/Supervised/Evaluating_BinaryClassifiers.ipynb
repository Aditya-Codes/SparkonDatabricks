{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Dataset source: https://archive.ics.uci.edu/ml/datasets/Adult <br/>\n",
    "PySpark ML Classifier Reference: https://spark.apache.org/docs/2.3.0/ml-classification-regression.html#classification <br/>\n",
    "<b> <i> Classifier Models Used: </i> </b> <br/>\n",
    "<ul>\n",
    "  <li> Logistic Regression </li>\n",
    "  <li> Naive Bayes </li>\n",
    "  <li> Decision Tree </li>\n",
    "  <li> Gradient-boosted Tree </li>\n",
    "  <li> Random Forest </li>\n",
    "  <li> Multilayer Perceptron </li>\n",
    "  <li> One-vs-All (Logistic Regression, Random Forest) </li>\n",
    "</ul>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computational and Visualisation Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ggplot import *\n",
    "\n",
    "# Pyspark Packages\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, desc, trim\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes, LogisticRegression, DecisionTreeClassifier, GBTClassifier, RandomForestClassifier, OneVsRest, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Import and Cleansing\n",
    "adult_gov_data = spark.read.csv('/databricks-datasets/adult/adult.data')\n",
    "country_codes = spark.sql('SELECT * FROM country_codes')\n",
    "\n",
    "adult_gov_data = adult_gov_data.select(col('_c0').cast('double').alias('age'), col('_c1').alias('workclass'), col('_c2').cast('double').alias('fnlwgt'), col('_c3').alias('education'), col('_c4').cast('double').alias('education_num'), col('_c5').alias('marital_status'),col('_c6').alias('occupation'), col('_c7').alias('relationship'), col('_c8').alias('race'), col('_c9').alias('sex'), col('_c10').cast('double').alias('capital_gain'), col('_c11').cast('double').alias('capital_loss'), col('_c12').cast('double').alias('hours_per_week'), col('_c13').alias('native_country'), col('_c14').alias('income'))\n",
    "adult_gov_data = adult_gov_data.withColumn('native_country', F.regexp_replace(col('native_country'), '-', ' '))\n",
    "adult_gov_data = adult_gov_data.withColumn('native_country', trim(col('native_country')))\n",
    "\n",
    "expanded_cols = adult_gov_data.columns + ['alpha_3_code', 'latitude', 'longitude']\n",
    "adult_gov_data_expanded = adult_gov_data.join(country_codes, adult_gov_data.native_country == country_codes.country, how='left')[expanded_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Viewing a sample of data\n",
    "display (adult_gov_data_expanded.sample(False, 0.01), 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summary Statistics of the ingested data\n",
    "display (adult_gov_data_expanded.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Average hours worked per week across geographies\n",
    "display(adult_gov_data_expanded.groupBy('alpha_3_code').agg(F.sum('hours_per_week').alias('total_hours')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing with Category-Indexing and One-Hot Encoding\n",
    "col_categorical = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
    "pipeline_steps = [] \n",
    "\n",
    "for column in col_categorical:\n",
    "    string_indexed = StringIndexer(inputCol=column, outputCol=column + \"Index\")\n",
    "    one_hot_encoded = OneHotEncoderEstimator(inputCols=[string_indexed.getOutputCol()], outputCols=[column + \"classVec\"])\n",
    "    pipeline_steps += [string_indexed, one_hot_encoded]\n",
    "    \n",
    "label_stringIdx = StringIndexer(inputCol=\"income\", outputCol=\"label\")\n",
    "pipeline_steps += [label_stringIdx]\n",
    "\n",
    "numerical_columns = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "assembler_col = [col + \"classVec\" for col in col_categorical] + numerical_columns\n",
    "assemblerModel = VectorAssembler(inputCols=assembler_col, outputCol=\"features\")\n",
    "pipeline_steps += [assemblerModel]\n",
    "\n",
    "# Applying the pipeline on the dataset\n",
    "pipelineInst = Pipeline (stages=pipeline_steps)\n",
    "pipelineModel = pipelineInst.fit (adult_gov_data_expanded)\n",
    "adult_gov_data_processed = pipelineModel.transform (adult_gov_data_expanded).select(adult_gov_data_expanded.columns + ['label', 'features'])\n",
    "train, test = adult_gov_data_processed.randomSplit([.75, .25], seed=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Summary statistics of the training dataset\n",
    "display (train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "display_cols = ['label', 'age', 'occupation', 'probability', 'prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Classifier Model\n",
    "lrInst = LogisticRegression(labelCol='label', featuresCol='features', maxIter=50)\n",
    "lrModel = lrInst.fit(train)\n",
    "lrPredictions = lrModel.transform(test)\n",
    "\n",
    "lrbceInst = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print (\"Model Accuracy = %.15f\" % lrbceInst.evaluate(lrPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictions against occupation for LR Classifier with max iteration = 50\n",
    "display (lrPredictions[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the best Linear Regression model\n",
    "lrpgInst = (ParamGridBuilder()\n",
    "             .addGrid(lrInst.regParam, [0.01, 0.5, 2.0])\n",
    "             .addGrid(lrInst.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .addGrid(lrInst.maxIter, [15, 30, 45])\n",
    "             .build())\n",
    "lrcvInst = CrossValidator(estimator=lrInst, estimatorParamMaps=lrpgInst, evaluator=lrbceInst, numFolds=5) #5 folds\n",
    "lrcvModel = lrcvInst.fit(train)\n",
    "lrcvPredictions = lrcvModel.transform(test)\n",
    "print ('Best Model Score: %.15f' % lrbceInst.evaluate(lrcvPredictions))\n",
    "print ('Best Model Intercept: %.15f' % lrcvModel.bestModel.intercept)\n",
    "new_frame_lrweights = sqlContext.createDataFrame([(float(w),) for w in lrcvModel.bestModel.coefficients], [\"Feature Weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature weights for the best LR Classifier model\n",
    "display(new_frame_lrweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictions against occupation for the best LR Classifier model\n",
    "display(lrcvPredictions[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes multinomial Classifier model with smoothing=2.0\n",
    "nbInst = NaiveBayes(labelCol='label', featuresCol='features', smoothing=2.0, modelType=\"multinomial\")\n",
    "nbModel = nbInst.fit(train)\n",
    "nbPredictions = nbModel.transform(test)\n",
    "\n",
    "nbmceInst = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print (\"Model Accuracy = %.15f\" % nbmceInst.evaluate(nbPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Occupation against Prediction for above NB classifier model\n",
    "display (nbPredictions[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating best NB Classifier model\n",
    "nbpgInst = (ParamGridBuilder()\n",
    "             .addGrid(nbInst.smoothing, [1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "             .build())\n",
    "nbcvInst = CrossValidator(estimator=nbInst, estimatorParamMaps=nbpgInst, evaluator=nbmceInst, numFolds=5) #5 folds\n",
    "nbcvModel = nbcvInst.fit(train)\n",
    "nbcvBestPredictions = nbcvModel.transform(test)\n",
    "print ('Best Model Score: %.15f' % nbmceInst.evaluate(nbcvBestPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Workclass against Predictions for the best NB classifier model\n",
    "display(nbcvBestPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-vs-All Classifier model fitted on best LR classifier model\n",
    "lrPrevBestModel = lrcvModel.bestModel\n",
    "ovalrInst = LogisticRegression(labelCol='label', featuresCol='features', fitIntercept=True, \n",
    "                               maxIter=lrPrevBestModel._java_obj.getMaxIter(), \n",
    "                               elasticNetParam=lrPrevBestModel._java_obj.getElasticNetParam(), \n",
    "                               regParam=lrPrevBestModel._java_obj.getRegParam())\n",
    "ovaInst = OneVsRest(classifier=ovalrInst)\n",
    "ovaModel = ovaInst.fit(train)\n",
    "ovaPredictions = ovaModel.transform(test)\n",
    "\n",
    "ovamceInst = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print (\"Model Accuracy = %.15f\" % ovamceInst.evaluate(ovaPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictions from One-vs-All Classifier model\n",
    "display (ovaPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree Classifier Model\n",
    "dtInst = DecisionTreeClassifier (labelCol=\"label\", featuresCol=\"features\", maxDepth=4)\n",
    "dtModel = dtInst.fit (train)\n",
    "dtPredictions = dtModel.transform (test)\n",
    "dtbceInst = BinaryClassificationEvaluator()\n",
    "print ('Model Fit Score: %.15f' % dtbceInst.evaluate(dtPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Occupation against Predictions for DT Classifier model\n",
    "display(dtPredictions[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating best Decision Tree classifier model\n",
    "dtpgInst = (ParamGridBuilder()\n",
    "             .addGrid(dtInst.maxDepth, [1, 3, 8, 12])\n",
    "             .addGrid(dtInst.maxBins, [25, 50, 90])\n",
    "             .build())\n",
    "dtcvInst = CrossValidator(estimator=dtInst, estimatorParamMaps=dtpgInst, evaluator=dtbceInst, numFolds=5) #5 folds\n",
    "dtcvModel = dtcvInst.fit(train)\n",
    "dtcvBestPredictions = dtcvModel.transform(test)\n",
    "print ('Best Model Score: %.15f' % dtbceInst.evaluate(dtcvBestPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Occupation against Predictions for the best DT Classifier model\n",
    "display(dtcvBestPredictions[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient-boosted Tree Classifier Model\n",
    "gbtInst = GBTClassifier (labelCol=\"label\", featuresCol=\"features\", maxIter=20, maxDepth=5)\n",
    "gbtModel = gbtInst.fit (train)\n",
    "gbtPredictions = gbtModel.transform (test)\n",
    "gbtmceInst = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "print ('Model Fit Score: %.15f' % gbtmceInst.evaluate(gbtPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Occupation against Prediction for DT Classifier model\n",
    "display(gbtPredictions[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating best Gradient-boosted tree classifier model\n",
    "gbtpgInst = (ParamGridBuilder()\n",
    "             .addGrid(gbtInst.maxDepth, [3, 5, 7])\n",
    "             .addGrid(gbtInst.maxIter, [25, 40, 50])\n",
    "             .build())\n",
    "gbtcvInst = CrossValidator(estimator=gbtInst, estimatorParamMaps=gbtpgInst, evaluator=gbtmceInst, numFolds=5) #5 folds\n",
    "gbtcvModel = gbtcvInst.fit(train)\n",
    "gbtcvBestPredictions = gbtcvModel.transform(test)\n",
    "print ('Best Model Score: %.15f' % gbtmceInst.evaluate(gbtcvBestPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample rows with prediction from the best GBT Classifier model\n",
    "display (gbtcvBestPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Classifier Model\n",
    "rfInst = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "rfModel = rfInst.fit(train)\n",
    "rfPredictions = rfModel.transform(test)\n",
    "rfbceInst = BinaryClassificationEvaluator()\n",
    "print ('Model Fit Score: %.15f' % rfbceInst.evaluate(rfPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Occupation against Prediction for RF Classifier model\n",
    "display (rfPredictions[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the best RF classifier model\n",
    "rfpgInst = (ParamGridBuilder()\n",
    "             .addGrid(rfInst.maxDepth, [1, 3, 8])\n",
    "             .addGrid(rfInst.maxBins, [25, 50])\n",
    "             .addGrid(rfInst.numTrees, [5, 20])\n",
    "             .build())\n",
    "rfcvInst = CrossValidator(estimator=rfInst, estimatorParamMaps=rfpgInst, evaluator=rfbceInst, numFolds=5)\n",
    "rfcvModel = rfcvInst.fit(train)\n",
    "rfcvBestPredictions = rfcvModel.transform(test)\n",
    "print ('Best Model Score: %.15f' % rfbceInst.evaluate(rfcvBestPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample subset of rows with prediction from RF Classifier model\n",
    "display (rfcvBestPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-vs-All Classifier model fitted on the best RF Classifier model\n",
    "rfPrevBestModel = rfcvModel.bestModel\n",
    "ovarfInst = RandomForestClassifier(labelCol='label', featuresCol='features',\n",
    "                               maxDepth=rfPrevBestModel._java_obj.getMaxDepth(), \n",
    "                               maxBins=rfPrevBestModel._java_obj.getMaxBins(), \n",
    "                               numTrees=rfPrevBestModel._java_obj.getNumTrees())\n",
    "ovarfInst = OneVsRest(classifier=ovarfInst)\n",
    "ovarfModel = ovarfInst.fit(train)\n",
    "ovarfPredictions = ovarfModel.transform(test)\n",
    "\n",
    "ovamceInst = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print (\"Model Accuracy = %.15f\" % ovamceInst.evaluate(ovarfPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample subset of rows along with predictions\n",
    "display (ovarfPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multilayer Perceptron Classifier\n",
    "layers = [train.schema[\"features\"].metadata[\"ml_attr\"][\"num_attrs\"], 20, 10, 2]\n",
    "mpcInst = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=451)\n",
    "mpcModel = mpcInst.fit(train)\n",
    "mpcPredictions = mpcModel.transform(test)\n",
    "mpcBce = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print (\"Model Accuracy = %.15f\" % mpcBce.evaluate(mpcPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income and Occupation against Prediction\n",
    "display (mpcPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating best MP Classifier\n",
    "mpcpgInst = (ParamGridBuilder()\n",
    "             .addGrid(mpcInst.maxIter, [50, 100, 150])\n",
    "             .addGrid(mpcInst.blockSize, [128, 256, 512])\n",
    "             .build())\n",
    "mpccvInst = CrossValidator(estimator=mpcInst, estimatorParamMaps=mpcpgInst, evaluator=mpcBce, numFolds=5)\n",
    "mpccvModel = mpccvInst.fit(train)\n",
    "mpccvBestPredictions = mpccvModel.transform(test)\n",
    "print (\"Best Model Accuracy Score = %.15f\" % mpcBce.evaluate(mpccvBestPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample subset of rows from the best MP Classifier model\n",
    "display (mpccvBestPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using best RF Classifier model for predictions - Accuracy:90.6%\n",
    "selectedModel = rfcvModel.bestModel\n",
    "selectedPredictions = selectedModel.transform(adult_gov_data_processed)\n",
    "print (\"Model Fit Score = \", rfbceInst.evaluate(selectedPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(selectedPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(selectedPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_comparison_df = spark.createDataFrame(pd.DataFrame({\n",
    "  'classifiers':['LR', 'NB', 'DT', 'GBT', 'RF', 'MLP', 'ovA-LR', 'ovA-RF'], \n",
    "  'accuracy_scores':[90.1, 78.8, 76.7, 85.5, 89.1, 76.5, 84.8, 84.8]\n",
    "}))\n",
    "display(classifier_comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We implemented all the classifiers available with the Pyspark ML module, and the RF classifier emerged with the best accuracy for this dataset with a score of 90.6%. We plan to implement XGBoost on the same data in the future notebooks. <br/> \n",
    "\n",
    "For the best models against each classifier, the below-mentioned accuracy scores were achieved: <br/>\n",
    "\n",
    "<ul>\n",
    "  <li> Logistic Regression - 90.1% </li>\n",
    "  <li> Naive Bayes - 78.8% </li>\n",
    "  <li> Decision Tree - 76.7% </li>\n",
    "  <li> Gradient-boosted Tree - 85.5% </li>\n",
    "  <li> Random Forest - 89.1% </li>\n",
    "  <li> Multilayer Perceptron - 76.5%</li>\n",
    "  <li> One-vs-All (Logistic Regression - 84.8%, Random Forest - 84.8%) </li>\n",
    "</ul>\n",
    "\n",
    "The published version of the notebook is available at - <br/> \n",
    "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3173713035751393/675963439015456/2308983777460038/latest.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "name": "Evaluating_BinaryClassifiers",
  "notebookId": 675963439015456
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
